{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TvYrQjdM9xVM"
      },
      "outputs": [],
      "source": [
        "path = \"./\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "afcm9vf69xVR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from numpy import argmax, array, mean\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "test_size = .2\n",
        "valid_size = .1\n",
        "seed = 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biCpAbRz9xVS"
      },
      "source": [
        "#### Load data from csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KWMLm-i_9xVT"
      },
      "outputs": [],
      "source": [
        "user_ratings_data = pd.read_csv(f\"{path}/user_ratings.csv\")\n",
        "users_data = pd.read_csv(f\"{path}/users.csv\")\n",
        "roars_data = pd.read_csv(f\"{path}/roars.csv\")\n",
        "\n",
        "users_preference = users_data[[f\"{i}\" for i in range(10)]]\n",
        "users_data[\"main_category\"] = [argmax(i) for i in users_preference.to_numpy()]\n",
        "\n",
        "names = users_data.columns.to_list()\n",
        "names[0] = \"user_id\"\n",
        "users_data.columns = names\n",
        "\n",
        "names = roars_data.columns.to_list()\n",
        "names[0] = \"roar_id\"\n",
        "roars_data.columns = names\n",
        "del names\n",
        "\n",
        "# merge in users_data\n",
        "user_ratings_data = pd.merge(user_ratings_data, users_data, on=\"user_id\")\n",
        "user_ratings_data = pd.merge(user_ratings_data, roars_data, on=\"roar_id\")\n",
        "\n",
        "# fix indexes in roars\n",
        "old_id = roars_data[\"roar_id\"].copy()\n",
        "roars_data[\"roar_id\"] = [i for i in range(len(old_id))]\n",
        "\n",
        "dict_roar_id = {}\n",
        "for i, value in enumerate(old_id):\n",
        "  dict_roar_id[value] = i\n",
        "\n",
        "user_ratings_data.roar_id = user_ratings_data[\"roar_id\"].map(dict_roar_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "b-VhvIUs9xVV"
      },
      "outputs": [],
      "source": [
        "X_train_full, X_test, Y_train_full, Y_test = train_test_split(user_ratings_data[[\"user_id\", \"roar_id\"]], user_ratings_data[\"rating\"], test_size=test_size , random_state=seed)\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_full, Y_train_full, test_size=valid_size, random_state=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ikAMkrc9xVa"
      },
      "source": [
        "#### Construct recommender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bxkiyoRr9xVa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-22 04:31:03.665480: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-06-22 04:31:03.665567: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ci6o5HTR9xVb"
      },
      "outputs": [],
      "source": [
        "class NeuMF:\n",
        "\n",
        "    def __init__(self, user_num, item_num):\n",
        "        \"\"\"\n",
        "            Neural Matrix Factorization is a neural network with the following architecture:\n",
        "            \n",
        "            |=========================================|\n",
        "            |  Legend:                                |\n",
        "            |  - Generic Matrix Factorization (GMF)   |\n",
        "            |  - Multilayer Perceptron (MLP)          |\n",
        "            |=========================================|\n",
        "            \n",
        "            \n",
        "            [[GMF]      [MLP]]\n",
        "            [   [Dense L]    ]\n",
        "            [     [Result]   ]\n",
        "        \"\"\"\n",
        "        latent_features = 8\n",
        "\n",
        "        # Input\n",
        "        user = Input(shape=(1,), dtype='int32')\n",
        "        item = Input(shape=(1,), dtype='int32')\n",
        "        \n",
        "        # User embedding for GMF\n",
        "        gmf_user_embedding = Embedding(user_num, latent_features, input_length=user.shape[1])(user)\n",
        "        gmf_user_embedding = Flatten()(gmf_user_embedding)\n",
        "\n",
        "        # Item embedding for GMF\n",
        "        gmf_item_embedding = Embedding(item_num, latent_features, input_length=item.shape[1])(item)\n",
        "        gmf_item_embedding = Flatten()(gmf_item_embedding)\n",
        "\n",
        "        # User embedding for MLP\n",
        "        mlp_user_embedding = Embedding(user_num, 32, input_length=user.shape[1])(user)\n",
        "        mlp_user_embedding = Flatten()(mlp_user_embedding)\n",
        "\n",
        "        # Item embedding for MLP\n",
        "        mlp_item_embedding = Embedding(item_num, 32, input_length=item.shape[1])(item)\n",
        "        mlp_item_embedding = Flatten()(mlp_item_embedding)\n",
        "\n",
        "        # GMF layers\n",
        "        gmf_mul =  Multiply()([gmf_user_embedding, gmf_item_embedding])\n",
        "\n",
        "        # MLP layers\n",
        "        mlp_concat = Concatenate()([mlp_user_embedding, mlp_item_embedding])\n",
        "        mlp_dropout = Dropout(0.2)(mlp_concat)\n",
        "\n",
        "        # Layer1\n",
        "        mlp_layer_1 = Dense(units=64, activation='relu', name='mlp_layer1')(mlp_dropout)  # (64,1)\n",
        "        mlp_dropout1 = Dropout(rate=0.2, name='dropout1')(mlp_layer_1)                    # (64,1)\n",
        "        mlp_batch_norm1 = BatchNormalization(name='batch_norm1')(mlp_dropout1)            # (64,1)\n",
        "\n",
        "        # Layer2\n",
        "        mlp_layer_2 = Dense(units=32, activation='relu', name='mlp_layer2')(mlp_batch_norm1)  # (32,1)\n",
        "        mlp_dropout2 = Dropout(rate=0.2, name='dropout2')(mlp_layer_2)                        # (32,1)\n",
        "        mlp_batch_norm2 = BatchNormalization(name='batch_norm2')(mlp_dropout2)                # (32,1)\n",
        "\n",
        "        # Layer3\n",
        "        mlp_layer_3 = Dense(units=16, activation='relu', name='mlp_layer3')(mlp_batch_norm2)  # (16,1)\n",
        "\n",
        "        # Layer4\n",
        "        mlp_layer_4 = Dense(units=8, activation='relu', name='mlp_layer4')(mlp_layer_3)       # (8,1)\n",
        "\n",
        "        # merge GMF + MLP\n",
        "        merged_vector = tf.keras.layers.concatenate([gmf_mul, mlp_layer_4])\n",
        "\n",
        "        # Output layer\n",
        "        output_layer = Dense(1, kernel_initializer='lecun_uniform', name='output_layer')(merged_vector) # 1,1 / h(8,1)\n",
        "\n",
        "        # Model\n",
        "        self.model = Model([user, item], output_layer)\n",
        "        self.model.compile(optimizer= 'adam', loss= 'msle')\n",
        "\n",
        "    def get_model(self):\n",
        "        model = self.model\n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFdb1VoSNIRE",
        "outputId": "72606475-386d-4d24-ed15-e29bc4851215"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "46769"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "roar_size = len(X_train[\"roar_id\"].unique())\n",
        "roar_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PW8Pi4S6U0UV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-22 04:31:35.210000: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2022-06-22 04:31:35.210080: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2022-06-22 04:31:35.210139: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (atp-ariel): /proc/driver/nvidia/version does not exist\n",
            "2022-06-22 04:31:35.275330: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "nmf = NeuMF(5000, roar_size)\n",
        "model = nmf.get_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5X-8mgz19xVd"
      },
      "outputs": [],
      "source": [
        "X = [X_train[\"user_id\"], X_train[\"roar_id\"]]\n",
        "X_v = (X_valid[\"user_id\"], X_valid[\"roar_id\"])\n",
        "X_t = (X_test[\"user_id\"], X_test[\"roar_id\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSfeIyxtOO59",
        "outputId": "b3867b58-4fc9-4da4-e4d7-bb146e421ac9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fc6b02cac10>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tf.keras.models.load_model(path + \"/neuMF\")\n",
        "model.load_weights(path + \"/neuMF_w\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1bgYECjTgq2x"
      },
      "outputs": [],
      "source": [
        "loss = [] \n",
        "val_loss = [] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkEqTTIi9xVd"
      },
      "outputs": [],
      "source": [
        "checkpoints = 10\n",
        "for i in range(checkpoints):\n",
        "  print(\"Iter\", i)\n",
        "  temp = model.fit(X, Y_train, epochs=10, batch_size=1024, validation_data=(X_v, Y_valid))\n",
        "  loss += temp.history[\"loss\"]\n",
        "  val_loss += temp.history[\"val_loss\"]\n",
        "  model.save(path + \"/neuMF\")\n",
        "  model.save_weights(path + \"/neuMF_w\")\n",
        "  plt.plot([i for i in range(len(loss))], loss, label=\"Training\")\n",
        "  plt.plot([i for i in range(len(val_loss))], val_loss, label=\"Validation\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hfmy8sSIjret"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50932/53885 [===========================>..] - ETA: 7s"
          ]
        }
      ],
      "source": [
        "a = model.predict(X_t)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL1V_aq6Krxe",
        "outputId": "5e67f93f-5339-4f0b-b87d-66bf7a99a9a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1724320,)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_t = Y_test.to_numpy()\n",
        "Y_t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "z_NPoDMeLG_n"
      },
      "outputs": [],
      "source": [
        "msle = tf.keras.losses.MeanSquaredLogarithmicError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN7VBja3eNjp",
        "outputId": "5dd8aa16-b342-4434-fb1e-d72d860da8ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.41354555\n"
          ]
        }
      ],
      "source": [
        "e = []\n",
        "for i in range(Y_t.shape[0]//30000):\n",
        "  e.append(msle(Y_t[30000*i: 30000*(i+1)], a[30000*i: 30000*(i+1)]).numpy())\n",
        "print(mean(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9alp9OLyhenX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "tfd.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
